{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1479c672-d411-4ced-b504-925ce87dfd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import collections\n",
    "import altair as alt\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "alt.data_transformers.disable_max_rows()\n",
    "ROOT_PATH = 'individual_root_path'\n",
    "DB_NAME = 'individual_db_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c366577-2124-4352-a0d8-b9688f7c3ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = ROOT_PATH\n",
    "db_path = DB_NAME\n",
    "connection_string = 'sqlite://' + root_path + db_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084ccf0a-8bdc-447e-9660-d8c06ae49226",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_TABLE = \"\"\"(SELECT job_id\n",
    ", user_id\n",
    ", queue_name\n",
    ", group_id\n",
    ", job_name\n",
    ", nodes\n",
    ", node_type\n",
    ", submit_time\n",
    ", start_time\n",
    ", end_time\n",
    ", requeue\n",
    ", used_walltime\n",
    ", ROUND((JULIANDAY(end_time)-JULIANDAY(start_time)) * 86400) AS run_s\n",
    ", ROUND((JULIANDAY(start_time)-JULIANDAY(submit_time)) * 86400) AS wait_s\n",
    "FROM total) AS t\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae411fc9-54df-4519-9f6d-a529f95d0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CONDITION = \"\"\"AND requeue = 0\n",
    "AND queue_name = 'normal'\n",
    "AND wait_s > 0\n",
    "AND start_time > submit_time\n",
    "AND end_time > start_time\n",
    "AND user_id IS NOT NULL\n",
    "AND job_name IS NOT NULL\n",
    "AND used_walltime < run_s\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cfec1a-3ac8-4fea-ba3c-e0d0fc1d79ac",
   "metadata": {},
   "source": [
    "## Comparison Between JOB and BoT\n",
    "\n",
    "We aim to determine whether the same job includes both normal jobs and BoT (Bag of Tasks) jobs.  \n",
    "Through this, we highlight the difficulties in analyzing jobs separately by distinguishing between normal jobs and BoT jobs.  \n",
    "\t•\tTotal number of jobs: 118,754  \n",
    "\t•\tJobs with BOT_TASKS_COUNT > 0 (a): 8,117  \n",
    "\t•\tJobs with NORMAL_JOB_COUNT > 0 (b): 184,505  \n",
    "\t•\tJobs with both (a) and (b): 4,951  \n",
    "\n",
    "However, when considering the total computing time (calculated as run_s * node_count):  \n",
    "\t•\tBOT_TASKS_COUNT total computing time: 2.8907 × 10¹⁰  \n",
    "\t•\tNORMAL_JOB_COUNT total computing time: 5.8115 × 10¹⁰  \n",
    "\n",
    "Based on wall time:  \n",
    "\t•\tBOT_TASKS_COUNT wall time: 9.4485 × 10⁹  \n",
    "\t•\tNORMAL_JOB_COUNT wall time: 1.1477 × 10¹⁰  \n",
    "\n",
    "Regarding the submit time distribution:  \n",
    "\t•\tOut of 653,088 submissions, 550,162 (84.2%) were submitted within 1,440 minutes (24 hours).  \n",
    "\t•\t477,845 submissions (73.2%) occurred within 60 minutes.  \n",
    "\t•\t369,712 submissions (56.6%) occurred within 1 minute.  \n",
    "\t•\t392,981 submissions (60.2%) occurred within 2 minutes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b9e135-5792-4258-b766-8dd07596637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMIT_DELAY_TIME = 60\n",
    "query = f\"\"\"\n",
    "WITH base AS (\n",
    "SELECT \n",
    "    t.*\n",
    "    , json_array_length(nodes) AS node_count\n",
    "FROM {BASE_TABLE}\n",
    "WHERE 1=1\n",
    "{BASE_CONDITION}\n",
    "), base_with_prev_submit_time AS (\n",
    "SELECT \n",
    "    base.*\n",
    "    , LAG(base.submit_time) OVER (PARTITION BY user_id, job_name ORDER BY submit_time ASC) AS prev_submit_time\n",
    "FROM base\n",
    "), base_with_session_flag AS (\n",
    "SELECT \n",
    "    base_with_prev_submit_time.* \n",
    "    , CASE \n",
    "        WHEN ROUND((JULIANDAY(submit_time)-JULIANDAY(prev_submit_time)) * 86400) < {SUBMIT_DELAY_TIME} THEN 0 \n",
    "        ELSE 1 \n",
    "    END AS is_new_session\n",
    "FROM base_with_prev_submit_time\n",
    "), base_with_session_id AS (\n",
    "SELECT \n",
    "    base_with_session_flag.*\n",
    "    , SUM(is_new_session) OVER (PARTITION BY user_id, job_name ORDER BY submit_time ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS session_id\n",
    "FROM base_with_session_flag\n",
    "), session AS (\n",
    "SELECT \n",
    "    user_id\n",
    "    , job_name\n",
    "    , session_id\n",
    "    , count(1) AS session_length\n",
    "    , sum(used_walltime) AS total_wall_time\n",
    "    , sum(node_count) AS node_count_sum\n",
    "    , sum(used_walltime * node_count) AS total_computing_time\n",
    "FROM base_with_session_id\n",
    "GROUP BY 1, 2, 3\n",
    ")\n",
    "SELECT \n",
    "    user_id\n",
    "    , job_name\n",
    "    , SUM(iif(session_length>1, session_length, 0)) AS BOT_TASKS_JOBS_COUNT\n",
    "    , SUM(iif(session_length>1, 1, 0)) AS BOT_TASKS_COUNT\n",
    "    , ROUND(SUM(iif(session_length>1, total_wall_time, 0))) AS BOT_TASKS_WALL_TIME\n",
    "    , ROUND(SUM(iif(session_length>1, total_computing_time, 0))) AS BOT_TASKS_COMPUTING_TIME\n",
    "    , SUM(iif(session_length=1, 1, 0)) AS NORMAL_JOB_COUNT\n",
    "    , ROUND(SUM(iif(session_length=1, total_wall_time, 0))) AS NORMAL_JOB_WALL_TIME\n",
    "    , ROUND(SUM(iif(session_length=1, total_computing_time, 0))) AS NORMAL_JOB_COMPUTING_TIME\n",
    "    , COUNT(1) AS TOTAL_JOB_COUNT\n",
    "    , SUM(node_count_sum) AS node_count_sum\n",
    "FROM session\n",
    "GROUP BY 1, 2\n",
    "\"\"\"\n",
    "job_bot_compare = pl.read_database_uri(query, connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30de17f9-97a3-4f36-b5e4-29d737a8e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_bot_compare.filter(pl.col('NORMAL_JOB_WALL_TIME')>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ca469f-eea4-4ba2-911c-15a40722071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(job_bot_compare.filter(pl.col('NORMAL_JOB_WALL_TIME')>0).filter(pl.col('BOT_TASKS_WALL_TIME')>0).select(pl.sum('session_length')))\n",
    "print(job_bot_compare.filter(pl.col('NORMAL_JOB_WALL_TIME')>0).select(pl.sum('NORMAL_JOB_COUNT')))\n",
    "print(job_bot_compare.filter(pl.col('BOT_TASKS_WALL_TIME')>0).select(pl.sum('BOT_TASKS_COUNT')))\n",
    "print(job_bot_compare.filter(pl.col('NORMAL_JOB_WALL_TIME')>0).select(pl.sum('node_count_sum')))\n",
    "print(job_bot_compare.filter(pl.col('BOT_TASKS_WALL_TIME')>0).select(pl.sum('node_count_sum')))\n",
    "print(len(job_bot_compare.filter(pl.col('NORMAL_JOB_WALL_TIME')>0)))\n",
    "print(len(job_bot_compare.filter(pl.col('BOT_TASKS_WALL_TIME')>0)))\n",
    "print(len(job_bot_compare))\n",
    "print(job_bot_compare.select(pl.sum('NORMAL_JOB_WALL_TIME')))\n",
    "print(job_bot_compare.select(pl.sum('BOT_TASKS_WALL_TIME')))\n",
    "print(job_bot_compare.select(pl.sum('NORMAL_JOB_COMPUTING_TIME')))\n",
    "print(job_bot_compare.select(pl.sum('BOT_TASKS_COMPUTING_TIME')))\n",
    "# 2.8907e10\n",
    "# 5.8115e10\n",
    "# 234587 + 12252 : 120s, 7.60개, 7.16개\n",
    "# 235349 + 10138 : 60s, 3.92개, 3.97개\n",
    "# 239186\n",
    "# 1124123\n",
    "# 245661\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3eee52-e7f3-43ea-929e-29726b06ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_bot_compare.filter(pl.col('BOT_TASKS_JOBS_COUNT')==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96198ffd-7cc2-4422-9ea4-5adbc22799fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "WITH base AS (\n",
    "SELECT \n",
    "    t.*\n",
    "    , json_array_length(nodes) AS node_count\n",
    "FROM {BASE_TABLE}\n",
    "WHERE 1=1\n",
    "{BASE_CONDITION}\n",
    "), base_with_prev_submit_time AS (\n",
    "SELECT \n",
    "    base.*\n",
    "    , LAG(base.submit_time) OVER (PARTITION BY user_id, job_name ORDER BY submit_time ASC) AS prev_submit_time\n",
    "FROM base\n",
    "), base_with_time_diff AS (\n",
    "SELECT \n",
    "    base_with_prev_submit_time.* \n",
    "    , CAST((JULIANDAY(submit_time)-JULIANDAY(prev_submit_time)) * 1440 * 10 AS int) / 10.0 AS submit_time_diff \n",
    "FROM base_with_prev_submit_time\n",
    ")\n",
    "SELECT submit_time_diff\n",
    "FROM base_with_time_diff\n",
    "WHERE submit_time_diff IS NOT NULL\n",
    "\"\"\"\n",
    "submit_time_diff = pl.read_database_uri(query, connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f7096d-1fc1-4221-b22f-4efa6c6dbe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(submit_time_diff.filter(pl.col('submit_time_diff')<60)).transform_window(\n",
    "    ecdf=\"cume_dist()\",\n",
    "    sort=[{\"field\": \"submit_time_diff\"}],\n",
    ").mark_line(\n",
    "    interpolate=\"step-after\"\n",
    ").encode(\n",
    "    x=\"submit_time_diff:Q\",\n",
    "    y=\"ecdf:Q\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae17be62-2d51-45bd-91e5-5e7d14786924",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_time_diff.filter(pl.col('submit_time_diff')<2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a684e772-beaf-4a39-a147-1f53687ec760",
   "metadata": {},
   "source": [
    "## SESSION_JOB Comparison\n",
    "\n",
    "Distribution of the number of sessions per user_id and job_name:  \n",
    "\t•\t99.4% of sessions fall within 20 sessions or fewer.  \n",
    "\t•\t98.5% of sessions fall within 10 sessions or fewer.  \n",
    "\t•\tThere are also occasional cases where the number of sessions exceeds 112. These correspond to unique (user_id, job_name) pairs, typically associated with jobs that generate log_wrf and log_real logs, occurring periodically.  \n",
    "\t•\tExceptionally, there are outlier cases with 1,853 and 1,224 sessions, which are considered anomalous data points  \n",
    "\n",
    "Number of jobs per session:  \n",
    "\t•\t99.1% of sessions contain 20 jobs or fewer.  \n",
    "\t•\t98.4% of sessions contain 10 jobs or fewer.  \n",
    "\t•\tExceptionally, there were cases where the number of jobs per session reached 3,764 and 3,288. These jobs were queries generated by the ad_system.  \n",
    "\t•\tAdditionally, there are rare cases where a session contains more than 250 jobs; however, at most, only four such sessions were observed.  \n",
    "\n",
    "⸻\n",
    "\n",
    "Comparison of session-wise sums:  \n",
    "\t•\tComparison was conducted for wait_s sum, run_s sum, total_s sum, and think_time sum per session.  \n",
    "\t•\tIt was found that in most sessions, think_time dominates the total_time.  \n",
    "\t•\tWhen think_time is excluded, wait_time and run_time show proportionality.  \n",
    "\t•\tThe correlation coefficient between total_time and think_time is extremely high, reaching 0.999.  \n",
    "\t•\tThe correlation between run_s and wait_s is about 0.118, indicating a weak linear relationship.  \n",
    "\n",
    "Although the Pearson correlation coefficient between run_time and wait_time is low, linear regression analysis shows that the gap until the next session increases as wait_time and run_time increase.  \n",
    "If we can analyze sessions of jobs in advance, it becomes possible to predict the timing of the next session and prepare in advance accordingly.  \n",
    "\n",
    "⸻\n",
    "\n",
    "Comparison of session-wise total_computing_time sums  \n",
    "\n",
    "Example:  \n",
    "\t•\tuser_3: “e1165a14” – “case1insul”  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b148e-c3c4-4155-99ed-e3d2f180fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "WITH base AS (\n",
    "SELECT \n",
    "    t.*\n",
    "    , json_array_length(nodes) AS node_count\n",
    "    , MAX(end_time) OVER (PARTITION BY user_id, job_name ORDER BY submit_time ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS max_end_time\n",
    "FROM {BASE_TABLE}\n",
    "WHERE 1=1\n",
    "{BASE_CONDITION}\n",
    "), base_with_prev_end_time AS (\n",
    "SELECT \n",
    "    base.*\n",
    "    , LAG(base.max_end_time) OVER (PARTITION BY user_id, job_name ORDER BY submit_time ASC) AS prev_end_time\n",
    "FROM base\n",
    "), base_with_session_flag AS (\n",
    "SELECT \n",
    "    base_with_prev_end_time.*\n",
    "    , CASE \n",
    "        WHEN prev_end_time > submit_time THEN 0 \n",
    "        ELSE 1 \n",
    "    END AS is_new_session\n",
    "    , MAX(ROUND((JULIANDAY(start_time)-JULIANDAY(prev_end_time)) * 86400), 0) AS additional_wait_s\n",
    "FROM base_with_prev_end_time\n",
    "), base_with_session_id AS (\n",
    "SELECT \n",
    "    base_with_session_flag.*\n",
    "    , CASE WHEN\n",
    "        is_new_session == 1 THEN wait_s\n",
    "        ELSE additional_wait_s\n",
    "    END AS new_wait_s\n",
    "    , SUM(is_new_session) OVER (PARTITION BY user_id, job_name ORDER BY submit_time ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS session_id\n",
    "FROM base_with_session_flag\n",
    "), session AS (\n",
    "SELECT \n",
    "    user_id\n",
    "    , job_name\n",
    "    , session_id\n",
    "    , count(1) AS session_length\n",
    "    , count(1) AS session_length_for_sum\n",
    "    , SUM(new_wait_s) AS session_total_wait_time\n",
    "    , sum(used_walltime) * 1.0 AS total_wall_time\n",
    "    , sum(used_walltime * node_count) * 1.0 AS total_computing_time\n",
    "    , MIN(submit_time) AS first_submit_time\n",
    "    , MIN(start_time) AS first_start_time\n",
    "    , MAX(end_time) AS last_end_time\n",
    "    , MIN(node_count) AS min_node_count\n",
    "    , MAX(node_count) AS max_node_count\n",
    "FROM base_with_session_id\n",
    "GROUP BY 1, 2, 3\n",
    "), session_with_rn AS (\n",
    "SELECT \n",
    "    *\n",
    "    , row_number() over (PARTITION BY user_id, job_name ORDER BY first_submit_time ASC) AS rn\n",
    "    , ROUND((JULIANDAY(last_end_time)-JULIANDAY(first_submit_time)) * 86400) - session_total_wait_time AS session_total_run_time\n",
    "FROM session\n",
    "), session_with_think_time AS (\n",
    "SELECT \n",
    "    t1.*\n",
    "    , CASE WHEN\n",
    "        t2.rn IS NULL THEN -1\n",
    "        ELSE ROUND((JULIANDAY(t2.first_submit_time)-JULIANDAY(t1.last_end_time)) * 86400) \n",
    "    END AS session_gap_time\n",
    "    , CASE WHEN\n",
    "        t2.rn IS NULL THEN -1 \n",
    "        ELSE ROUND((JULIANDAY(t2.first_submit_time)-JULIANDAY(t1.first_submit_time)) * 86400)\n",
    "    END AS session_total_time\n",
    "FROM session_with_rn AS t1 \n",
    "    LEFT JOIN session_with_rn AS t2 \n",
    "    ON t1.rn+1 = t2.rn AND t1.user_id = t2.user_id AND t1.job_name = t2.job_name\n",
    ")\n",
    "SELECT\n",
    "    *\n",
    "    , session_total_wait_time AS total_wait_time\n",
    "    , session_total_time AS total_time\n",
    "    , session_total_run_time AS total_execution_time\n",
    "    , session_total_wait_time/session_total_time*100 AS wait_for_total\n",
    "    , session_gap_time/session_total_time*100 AS gap_for_total\n",
    "    , session_total_run_time/session_total_time*100 AS execution_for_total\n",
    "FROM session_with_think_time\n",
    "WHERE 1=1\n",
    "\"\"\"\n",
    "session_job = pl.read_database_uri(query, connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709e275b-52ee-4d44-abd3-8f30ed48790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9ef5d8-b30e-4cb7-b158-46975dfc0979",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = f\"\"\"WITH base AS (\n",
    "SELECT \n",
    "    t.*\n",
    "    , json_array_length(nodes) AS node_count\n",
    "    , MAX(end_time) OVER (PARTITION BY user_id, job_name ORDER BY submit_time ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS max_end_time\n",
    "FROM {BASE_TABLE}\n",
    "WHERE 1=1\n",
    "{BASE_CONDITION}\n",
    ")\n",
    "SELECT *\n",
    "FROM base\n",
    "\"\"\"\n",
    "data_tt = pl.read_database_uri(tt, connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14ac901-60e6-4646-9bfc-c1cd6e7ea69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count1, count2 = 0, 0\n",
    "for row in session_job.filter(pl.col('session_gap_time')>-1).rows(named=True):\n",
    "    count1 += 1\n",
    "    if row['session_gap_time'] >= (row['total_wait_time'] + row['total_execution_time']) * 10:\n",
    "        count2 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd13b3ab-aea1-4944-80a2-5643c54d57fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_job.filter(pl.col('user_id')=='e1165a14').filter(pl.col('session_length')>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491ba063-c831-49b3-8479-fe7439555897",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_set = collections.defaultdict(int)\n",
    "for row in session_job.filter(pl.col('session_id')>=100).rows(named=True):\n",
    "    unique_set[(row['user_id'], row['job_name'])] = max(unique_set[(row['user_id'], row['job_name'])], row['session_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d227553f-b0c0-4f8a-9c60-9582bc39f702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_id, job_name 별 세션 개수\n",
    "session_count = session_job.group_by('user_id', 'job_name').len()\n",
    "# alt.Chart(session_count.filter(pl.col('len')<21)).mark_bar().encode(\n",
    "#     alt.X(\"len:N\", axis=alt.Axis(title='Session Count')),\n",
    "#     alt.Y(\"count()\", axis=alt.Axis(title='Unique (User Id, Job Name) Count'))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4220cd-fb4b-412d-9252-5827740fef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_job2 = session_job.group_by('session_length').agg(pl.col(\"session_length_for_sum\").sum())\n",
    "new_user_job2 = new_user_job2.with_columns((pl.col(\"session_length_for_sum\") / 1121803).alias(\"ratio\"))\n",
    "new_user_job2 = new_user_job2.with_columns(pl.lit(\"User-Job Pair\").alias(\"Grouping Condition\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a70f0c3-34d1-48a3-bada-5e41a639ccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_count_figure2 = alt.Chart(new_user_job2.filter(pl.col('session_length')<=1000).filter(pl.col('session_length')>=1)).mark_line().properties(\n",
    "    width=400,\n",
    "    height=130,\n",
    ").transform_window(\n",
    "    sort=[{'field': 'session_length'}],\n",
    "    cumulative_wheat='sum(ratio)'\n",
    ").encode(\n",
    "    alt.X(\"session_length:Q\", axis=alt.Axis(title='Job Count', labelFontSize=13, titleFontSize=13, labelAngle=0, values=[100*i for i in range(11)])),\n",
    "    alt.Y(\"cumulative_wheat:Q\", axis=alt.Axis(title='Probability', labelFontSize=13, titleFontSize=13)),\n",
    "    alt.Color(\"Grouping Condition\").legend(orient=\"top\", labelFontSize=13, labelLimit=200, titleFontSize=0\n",
    "                                 , direction='horizontal', titleOrient='left', labelFontWeight = 'bold')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179f1214-50c2-419c-9e65-236a0e1c7688",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_count_figure2 + job_count_figure + group_count_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079d3a1f-6e42-47ed-b99f-91df0c5b59e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(job_count_figure2 + job_count_figure + group_count_figure).save('job_count.pdf', ppi=1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3f90b1-89ea-4771-a129-b666fb1786ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_job2.filter(pl.col('session_length')==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d62b68-e547-4f23-93cd-6f6bb5a6ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_count = session_job.group_by('user_id', 'job_name').len()\n",
    "session_sum = session_job.group_by('user_id', 'job_name').sum()\n",
    "joined = session_count.join(session_sum, on=['user_id','job_name'])\n",
    "distribution_data = []\n",
    "def add_data_to_dict(session_length, category, proportion, list_v):\n",
    "    tmp = {}\n",
    "    tmp['session_count'] = session_length\n",
    "    tmp['category'] = category\n",
    "    tmp['proportion'] = proportion\n",
    "    list_v.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431ace8d-4ce6-4dec-b888-844e0be5a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_lengths = {}\n",
    "total = 0\n",
    "for k, v in session_count.group_by('len').count().rows():\n",
    "    session_lengths[k] = v\n",
    "    total += v\n",
    "tmp = 0\n",
    "for k in sorted(session_lengths.keys()):\n",
    "    tmp += session_lengths[k]\n",
    "    add_data_to_dict(k, 'count', session_lengths[k]/total*100, distribution_data)\n",
    "    if k>20: break\n",
    "# 20개를 기준으로 총 99.4%의 세션이 속하고,\n",
    "# 10개를 기준으로는 총 98.5%의 세션이 속한다.\n",
    "\n",
    "# 예외적으로 1853, 1224 의 세션개수를 가진 데이터가 존재하는데 이러한 데이터는 예외 데이터이다.\n",
    "# 또한, 세션 개수가 112개 이상인 데이터도 간헐적으로 존재하는데 이 역시 유니크한 user_id, job_name 이 1개인 케이스로 예외라고 볼 수 있다. \n",
    "# 100 포함 해서 넘는가 250개 존재\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647372e3-9178-4849-813e-e9f76a33f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_lengths2 = collections.defaultdict(int)\n",
    "total = 0\n",
    "for values in joined.rows(named=True):\n",
    "    k, v = values['len'], values['total_wall_time']\n",
    "    session_lengths2[k] += v\n",
    "    total += v\n",
    "tmp = 0\n",
    "for k in sorted(session_lengths2.keys()):\n",
    "    tmp += session_lengths2[k]\n",
    "    add_data_to_dict(k, 'total_wall_time', session_lengths2[k]/total*100, distribution_data)\n",
    "    add_data_to_dict(k, 'AVG(total_wall_time)', session_lengths2[k]/session_lengths[k]/k, distribution_data)\n",
    "    if k>20: break\n",
    "session_lengths3 = collections.defaultdict(int)\n",
    "total = 0\n",
    "for values in joined.rows(named=True):\n",
    "    k, v = values['len'], values['total_computing_time']\n",
    "    session_lengths3[k] += v\n",
    "    total += v\n",
    "tmp = 0\n",
    "for k in sorted(session_lengths3.keys()):\n",
    "    tmp += session_lengths3[k]\n",
    "    add_data_to_dict(k, 'total_computing_time', session_lengths3[k]/total*100, distribution_data)\n",
    "    add_data_to_dict(k, 'AVG(total_computing_time)', session_lengths3[k]/session_lengths[k]/k, distribution_data)\n",
    "    if k>20: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4874521-4211-4ce7-ba1c-9ad6e428a884",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pl.DataFrame(distribution_data)\n",
    "new_dd = dd.filter(pl.col(\"category\").is_in([\"count\", \"total_computing_time\", \"total_wall_time\"]))\n",
    "\n",
    "distribution1 = alt.Chart(new_dd).mark_line().properties(\n",
    "    width=400,\n",
    "    height=130,\n",
    ").encode(\n",
    "    alt.X(\"session_count:N\", axis=alt.Axis(title='Session Count', labelFontSize=13, values=[1,5,10,15,20], titleFontSize=13, labelAngle=0)),\n",
    "    alt.Y(\"proportion:Q\", axis=alt.Axis(title='Proportion(%)', labelFontSize=13, titleFontSize=13)),\n",
    "    alt.Color(\"category\", sort=['total_wall_time', 'total_computing_time', 'count']).legend(orient=\"top\", labelFontSize=13, labelLimit=200, titleFontSize=0, labelFontWeight = 'bold'\n",
    "                                 , direction='horizontal', titleOrient='left', labelExpr=\"{'count':'Count', 'total_wall_time':'Wall Time', 'total_computing_time':'Total Computing Time'}[datum.label]\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6998f88d-f4a9-4a2c-b5b1-16bb1b9831e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_over_100 = 0\n",
    "for i in session_lengths:\n",
    "    if i >= 100:\n",
    "        count_over_100 += (i*session_lengths[i])\n",
    "        # print(i,session_lengths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b3de9c-ac38-4ad9-8066-285312c9b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_over_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e872974b-ce48-4176-8bd0-191b60d941b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_wall_time_over_100 = 0\n",
    "for i in session_lengths2:\n",
    "    if i >= 100:\n",
    "        total_wall_time_over_100 += session_lengths2[i]\n",
    "print('total_wall_time', total_wall_time_over_100/count_over_100)\n",
    "total_computing_time_over_100 = 0\n",
    "for i in session_lengths3:\n",
    "    if i >= 100:\n",
    "        total_computing_time_over_100 += session_lengths3[i]\n",
    "print('total_computing_time', total_computing_time_over_100/count_over_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9059eb-bc94-4920-a9ef-d342c1573a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in distribution_data:\n",
    "    if i['session_count'] == 1 and 'AVG' in i['category']:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb2821-ec8b-4fac-b6be-f0764a260504",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution1.save('proportion.pdf', ppi=1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6075735d-dce9-4967-93cb-710b67d6d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_total_wall_time = new_dd.filter(pl.col('category')=='AVG(total_wall_time)').with_columns(\n",
    "    (pl.col('category')+'_ratio').alias('category2'),\n",
    "    (pl.col('proportion')/40844.523282).alias('proportion2'),\n",
    ").drop('proportion','category').rename({'category2':'category','proportion2':'proportion'})\n",
    "\n",
    "ratio_total_computing_time = new_dd.filter(pl.col('category')=='AVG(total_computing_time)').with_columns(\n",
    "    (pl.col('category')+'_ratio').alias('category2'),\n",
    "    (pl.col('proportion')/180571.105693).alias('proportion2'),\n",
    ").drop('proportion','category').rename({'category2':'category','proportion2':'proportion'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a17973-b2b3-4f78-9689-e464da60736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dd2 = pl.concat([ratio_total_wall_time, ratio_total_computing_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8fc9ff-6c53-4815-8010-57b99e0208d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.filter(pl.col('session_count')<=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8796e54-be28-4c9b-bc49-124c3ee1178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pl.DataFrame(distribution_data)\n",
    "new_dd = dd.filter(pl.col(\"category\").is_in([\"AVG(total_computing_time)\", \"AVG(total_wall_time)\"]))\n",
    "distribution2 = alt.Chart(new_dd).mark_line().properties(\n",
    "    width=400,\n",
    "    height=130\n",
    ").transform_calculate(\n",
    "    hour='datum.proportion/60/60/24',\n",
    ").encode(\n",
    "    alt.X(\"session_count:N\", axis=alt.Axis(title='Session Count', labelFontSize=13, values=[1,5,10,15,20], titleFontSize=13, labelAngle=0)),\n",
    "    alt.Y(\"hour:Q\", axis=alt.Axis(title='Time(Day)', labelFontSize=13, titleFontSize=13, labelAngle=-90)),\n",
    "    alt.Color(\"category\", sort=['total_wall_time', 'total_computing_time']).legend(orient=\"top\", labelFontSize=13, labelLimit=200, titleFontSize=0, labelFontWeight = 'bold'\n",
    "                                 , direction='horizontal', titleOrient='left', labelExpr=\"{'count':'count', 'AVG(total_wall_time)':'Wall Time', 'AVG(total_computing_time)':'Total Computing Time', 'AVG(total_computing_time)_ratio':'Total Computing Time(Ratio)'}[datum.label]\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2077c8-0653-432d-8d5d-eff15762f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45a3aae-1950-47fc-9cb3-06ee2c1a021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution2.save('average_for_session_count.pdf', ppi=1600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d855ec74-b680-4ba4-b450-3a952d375f2b",
   "metadata": {},
   "source": [
    "### Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e92669-89da-431a-a3f3-8b6579a3b458",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "WITH base AS (\n",
    "SELECT \n",
    "    t.*\n",
    "    , json_array_length(nodes) AS node_count\n",
    "    , MAX(end_time) OVER (PARTITION BY user_id, job_name ORDER BY submit_time ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS max_end_time\n",
    "FROM {BASE_TABLE}\n",
    "WHERE 1=1\n",
    "{BASE_CONDITION}\n",
    "), base_with_prev_end_time AS (\n",
    "SELECT \n",
    "    base.*\n",
    "    , LAG(base.max_end_time) OVER (PARTITION BY user_id, job_name ORDER BY submit_time ASC) AS prev_end_time\n",
    "FROM base\n",
    "), base_with_session_flag AS (\n",
    "SELECT \n",
    "    base_with_prev_end_time.*\n",
    "    , CASE \n",
    "        WHEN prev_end_time > submit_time THEN 0 \n",
    "        ELSE 1 \n",
    "    END AS is_new_session\n",
    "    , MAX(ROUND((JULIANDAY(start_time)-JULIANDAY(prev_end_time)) * 86400), 0) AS additional_wait_s\n",
    "FROM base_with_prev_end_time\n",
    "), base_with_session_id AS (\n",
    "SELECT \n",
    "    base_with_session_flag.*\n",
    "    , CASE WHEN\n",
    "        is_new_session == 1 THEN wait_s\n",
    "        ELSE additional_wait_s\n",
    "    END AS new_wait_s\n",
    "    , SUM(is_new_session) OVER (PARTITION BY user_id, job_name ORDER BY submit_time ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS session_id\n",
    "FROM base_with_session_flag\n",
    "), session AS (\n",
    "SELECT \n",
    "    user_id\n",
    "    , job_name\n",
    "    , session_id\n",
    "    , count(1) AS session_length\n",
    "    , count(1) AS session_length_for_sum\n",
    "    , SUM(new_wait_s) AS session_total_wait_time\n",
    "    , sum(used_walltime) * 1.0 AS total_wall_time\n",
    "    , sum(used_walltime * node_count) * 1.0 AS total_computing_time\n",
    "    , MIN(submit_time) AS first_submit_time\n",
    "    , MIN(start_time) AS first_start_time\n",
    "    , MAX(end_time) AS last_end_time\n",
    "    , MIN(node_count) AS min_node_count\n",
    "    , MAX(node_count) AS max_node_count\n",
    "FROM base_with_session_id\n",
    "GROUP BY 1, 2, 3\n",
    "), session_with_rn AS (\n",
    "SELECT \n",
    "    *\n",
    "    , row_number() over (PARTITION BY user_id, job_name ORDER BY first_submit_time ASC) AS rn\n",
    "    , ROUND((JULIANDAY(last_end_time)-JULIANDAY(first_submit_time)) * 86400) - session_total_wait_time AS session_total_run_time\n",
    "FROM session\n",
    "), session_with_think_time AS (\n",
    "SELECT \n",
    "    t1.*\n",
    "    , CASE WHEN\n",
    "        t2.rn IS NULL THEN -1\n",
    "        ELSE ROUND((JULIANDAY(t2.first_submit_time)-JULIANDAY(t1.last_end_time)) * 86400) \n",
    "    END AS session_gap_time\n",
    "    , CASE WHEN\n",
    "        t2.rn IS NULL THEN -1 \n",
    "        ELSE ROUND((JULIANDAY(t2.first_submit_time)-JULIANDAY(t1.first_submit_time)) * 86400)\n",
    "    END AS session_total_time\n",
    "FROM session_with_rn AS t1 \n",
    "    LEFT JOIN session_with_rn AS t2 \n",
    "    ON t1.rn+1 = t2.rn AND t1.user_id = t2.user_id AND t1.job_name = t2.job_name\n",
    ")\n",
    "SELECT\n",
    "    user_id\n",
    "    , job_name\n",
    "    , MAX(session_id) AS session_count\n",
    "    , SUM(total_wall_time) AS total_wall_time\n",
    "    , SUM(total_computing_time) AS total_computing_time\n",
    "    , SUM(total_wall_time) / SUM(session_length) AS avg_total_wall_time\n",
    "    , SUM(total_computing_time) / SUM(session_length) AS avg_total_computing_time\n",
    "FROM session_with_think_time\n",
    "WHERE 1=1\n",
    "GROUP BY 1, 2\n",
    "\"\"\"\n",
    "stats = pl.read_database_uri(query, connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68c5463-b578-44ee-a76e-182fadc9f043",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_oneway(stats.filter(pl.col('session_count')==1).select('avg_total_wall_time'), stats.filter(pl.col('session_count')==2).select('avg_total_wall_time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7121aec5-4dbe-42e5-82b0-6f36b00d2b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_lengths = {}\n",
    "total = 0\n",
    "for k, v in session_job.group_by('session_length').count().rows():\n",
    "    job_lengths[k] = v\n",
    "    total += v\n",
    "tmp = 0\n",
    "for k in sorted(job_lengths.keys()):\n",
    "    tmp += job_lengths[k]\n",
    "    print(k, job_lengths[k], tmp, tmp/total*100)\n",
    "\n",
    "# 20개를 기준으로 총 99.1%의 세션이 속하고,\n",
    "# 10개를 기준으로는 총 98.4%의 세션이 속한다.\n",
    "# 예외적으로 3764, 3288 의 Job 개수를 가진 데이터가 존재하였다.\n",
    "# 또한, Job의 개수가 250개 이상인 데이터도 간헐적으로 존재하는데 이러한 케이스는 많아야 4개의 세션이 존재하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c1d5b9-4fc2-4dad-a84b-a703a15dcb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(session_job).mark_circle().encode(\n",
    "    alt.X(alt.repeat(\"column\"), type='quantitative').scale(type=\"log\"),\n",
    "    alt.Y(alt.repeat(\"row\"), type='quantitative'),\n",
    "    color='Origin:N'\n",
    ").properties(\n",
    "    width=150,\n",
    "    height=150\n",
    ").repeat(\n",
    "    row=['session_total_time', 'session_total_run_time', 'session_total_wait_time', 'session_think_time'],\n",
    "    column=['session_think_time', 'session_total_wait_time', 'session_total_run_time', 'session_total_time']\n",
    ").interactive()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09654316-8302-433f-9ceb-51398b540f58",
   "metadata": {},
   "source": [
    "### Distribution of wait, run, think, total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388c476-4822-4356-b512-345665cabbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_job.select('session_total_run_time', 'session_total_wait_time').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c750bd4-d661-4804-aa2a-2cbf09b52192",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_job.filter(pl.col('session_total_time')>0).select('session_total_time', 'session_gap_time').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e663f04a-bc75-43c9-8482-696dc2ebbc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = session_job.select('total_wait_time').with_columns(pl.lit('TWT').alias(\"time_column\")).rename({'total_wait_time':'value'})\n",
    "name_maps = {\n",
    "    'total_execution_time':'TET',\n",
    "    'session_gap_time':'SGT',\n",
    "    'total_time':'TT'\n",
    "}\n",
    "for time_column in ['total_execution_time'\n",
    "                    , 'session_gap_time'\n",
    "                    , 'total_time'\n",
    "                   ]:\n",
    "    new_df = session_job.select(time_column).filter(pl.col(time_column)>0).with_columns(pl.lit(name_maps[time_column]).alias(\"time_column\")).rename({time_column:'value'})\n",
    "    start = pl.concat([start, new_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12542565-47e2-4e07-96b5-3d7d2de0c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "base1 = alt.LayerChart(data=start).transform_aggregate(\n",
    "    min=\"min(value)\",\n",
    "    max=\"max(value)\",\n",
    "    mean=\"mean(value)\",\n",
    "    median=\"median(value)\",\n",
    "    q1=\"q1(value)\",\n",
    "    q3=\"q3(value)\",\n",
    "    groupby=[\"time_column\"]\n",
    ").encode(\n",
    "    alt.Y(\"time_column:N\", axis=alt.Axis(title='Time Metric', labelFontSize=12, titleFontSize=12), sort=[\"TWT\", \"TET\", \"SGT\", \"TT\"]),\n",
    "    alt.X(\"value:Q\", axis=alt.Axis(title='Time(Seconds)', labelFontSize=12, titleFontSize=12, values=[1,10,100,1000,10000,100000,1000000,10000000])).scale(zero=False, type='log'),\n",
    ").add_layers(\n",
    "    alt.Chart().mark_rule().encode(x='min:Q', x2='max:Q'),\n",
    "    alt.Chart().mark_bar(width=15).encode(alt.Color(\"time_column:N\").legend(None), x='q1:Q', x2='q3:Q'),\n",
    "    alt.Chart().mark_tick(color='white', width=20).encode(x='median:Q'),\n",
    "    alt.Chart().mark_circle(color='black').encode(x='mean:Q')\n",
    ").configure(\n",
    "    numberFormat='.2s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10742d3-4532-49f1-9e69-9158f2ad3c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df389535-305c-486e-b073-44af5d92cbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base1.save('time_distribution.pdf', ppi=1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c4f0a7-3e5b-4895-bb8c-04daf1b2466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_wait_time >= 1M seconds\n",
    "# session_job.filter(pl.col('total_wait_time')>1_000_000).filter(pl.col('session_length')>1).filter(pl.col('total_wall_time')<100000).sum()\n",
    "for row in session_job.filter(pl.col('total_wait_time')>1_000_000).filter(pl.col('session_length')>1).rows(named=True):\n",
    "    print(row['job_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58682fe0-8974-490f-8afe-4aaee3c027a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_execution_time >= 1M seconds\n",
    "cnt = 0\n",
    "for row in session_job.filter(pl.col('total_execution_time')>1000000).sort('session_length', descending=True).rows(named=True):\n",
    "    # print(row['user_id'], row['job_name'], row['session_length'])\n",
    "    # if row['session_length']<100: break\n",
    "    if row['session_length']<100:\n",
    "        cnt += row['session_length']\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ced13c-ea1a-4260-b91d-25f46800a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session_gap_time >= 10M seconds\n",
    "cnt = 0\n",
    "for row in session_job.filter(pl.col('session_gap_time')>10_000_000).sort('session_length', descending=True).rows(named=True):\n",
    "    # print(row['user_id'], row['job_name'], row['session_length'])\n",
    "    # if cnt == 100:\n",
    "    #     break\n",
    "    cnt += row['session_length']\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00745fbe-7f5c-4274-823d-3ec378a8b99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = ['total_wait_time'\n",
    "         , 'total_execution_time'\n",
    "         , 'session_gap_time'\n",
    "         , 'total_time'\n",
    "         # , 'total_wall_time'\n",
    "         # , 'total_computing_time'\n",
    "        ]\n",
    "name_maps = {\n",
    "    'total_wait_time':'TWT',\n",
    "    'total_execution_time':'TET',\n",
    "    'session_gap_time':'SGT',\n",
    "    'total_time':'TT'\n",
    "}\n",
    "def get_corr(df, time1, time2):\n",
    "    df = df.filter(pl.col(time1)>0).filter(pl.col(time2)>0)\n",
    "    corr = df.select(pl.corr(time1,time2)).row(index=0)[0]\n",
    "    return corr\n",
    "\n",
    "values = {\n",
    "    'time1': [],\n",
    "    'time2': [],\n",
    "    'corr':[]\n",
    "}\n",
    "for t1 in range(len(times)):\n",
    "    for t2 in range(len(times)):\n",
    "        time1 = times[t1]\n",
    "        time2 = times[t2]\n",
    "        values['time1'].append(name_maps[time1])\n",
    "        values['time2'].append(name_maps[time2])\n",
    "        values['corr'].append(get_corr(session_job, time1, time2))\n",
    "corr_df = pl.DataFrame(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf65b6b-b334-486e-91c0-ed0c12044934",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_distribution_base2 = alt.Chart(corr_df).mark_rect().encode(\n",
    "    alt.X(\"time1:N\", axis=alt.Axis(title='Times', labelFontSize=13, titleFontSize=0), sort=[\"TWT\", \"TET\", \"SGT\", \"TT\"]),\n",
    "    alt.Y(\"time2:N\", axis=alt.Axis(title='Times', labelFontSize=13, titleFontSize=0), sort=[\"TWT\", \"TET\", \"SGT\", \"TT\"]),\n",
    "    alt.Color('corr:Q', bandPosition=0.5).legend(orient=\"right\", labelFontSize=13, labelLimit=200, titleFontSize=13)\n",
    ").properties(\n",
    "title = \"Entire Dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413caf5b-ef7f-4eeb-9ee3-dd0388f72cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_distribution_base2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca0c7d6-bd62-4283-a362-f672878c4b05",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f25c239-7f3d-4881-9872-3fbbd46b0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1b8a38-7750-4bc7-b732-afd432f4a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elbow\n",
    "sse = {}\n",
    "for k in range(1, 10):\n",
    "    kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=1000, random_state=0).fit(session_job_kmeans.select('wait_for_total', 'run_for_total', 'think_for_total'))\n",
    "    sse[k] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center\n",
    "plt.figure()\n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a901a67-6820-44a1-b619-178c3c20e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_job_kmeans = session_job.filter(pl.col('session_total_time')>0)\n",
    "kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300, random_state=0)\n",
    "kmeans.fit(session_job_kmeans.select('wait_for_total', 'execution_for_total', 'gap_for_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b26eac-130b-44c8-8b94-8fe703643ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_with_label = session_job_kmeans.with_columns(pl.Series(name=\"label\", values=kmeans.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c575ae57-0270-4af9-b409-b9c9d6bba5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plots = []\n",
    "for i in range(3):\n",
    "    session_with_label_filter = session_with_label.filter(pl.col('label')==i)\n",
    "    start = session_with_label_filter.select('total_wait_time').with_columns(pl.lit('0_total_wait_time').alias(\"time_column\")).rename({'total_wait_time':'value'})\n",
    "    order = 1\n",
    "    for time_column in ['total_execution_time'\n",
    "                        , 'session_gap_time'\n",
    "                        , 'total_time'\n",
    "                        # , 'total_wall_time'\n",
    "                        # , 'total_computing_time'\n",
    "                       ]:\n",
    "        new_df = session_with_label_filter.select(time_column).filter(pl.col(time_column)>0).with_columns(pl.lit(f'{order}_{time_column}').alias(\"time_column\")).rename({time_column:'value'})\n",
    "        start = pl.concat([start, new_df])\n",
    "        order += 1\n",
    "    base1 = alt.Chart(start).mark_boxplot(extent=\"min-max\").encode(\n",
    "    alt.X(\"time_column:N\", axis=alt.Axis(title='Times')),\n",
    "    alt.Y(\"value:Q\", axis=alt.Axis(title='Value Distribution')).scale(zero=False, type='log'),\n",
    "    alt.Color(\"time_column:N\").legend(None),\n",
    "    ).properties(\n",
    "    height=200\n",
    ")\n",
    "    box_plots.append(base1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8f6e4b-7c7f-45b9-8667-048fcafe9fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_with_label.filter(pl.col('label')==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c582c3-40ff-4405-9e0b-db892f7ccb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_with_label = {}\n",
    "for i in range(3):\n",
    "    value_with_label[i] = {\n",
    "    'time1': [],\n",
    "    'time2': [],\n",
    "    'corr':[]\n",
    "    }\n",
    "    session_with_label_filter = session_with_label.filter(pl.col('label')==i)\n",
    "    for t1 in range(len(times)):\n",
    "        for t2 in range(len(times)):\n",
    "            time1 = times[t1]\n",
    "            time2 = times[t2]\n",
    "            value_with_label[i]['time1'].append(name_maps[time1])\n",
    "            value_with_label[i]['time2'].append(name_maps[time2])\n",
    "            value_with_label[i]['corr'].append(get_corr(session_with_label_filter, time1, time2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10cb080-1b91-40fb-ad71-07b041e341f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = []\n",
    "titles = [\"High Wait\", \"High Gap\", \"High Execution\"]\n",
    "for i in range(3):\n",
    "    corr_df = pl.DataFrame(value_with_label[i])\n",
    "    base = alt.Chart(corr_df).mark_rect().encode(\n",
    "    alt.X(\"time1:N\", axis=alt.Axis(title='Times', labelFontSize=13, titleFontSize=0), sort=[\"TWT\", \"TET\", \"SGT\", \"TT\"]),\n",
    "    alt.Y(\"time2:N\", axis=alt.Axis(title='Times', labelFontSize=13, titleFontSize=0), sort=[\"TWT\", \"TET\", \"SGT\", \"TT\"]),\n",
    "    alt.Color('corr:Q')\n",
    "    ).properties(\n",
    "    title = titles[i]\n",
    "    )\n",
    "    corrs.append(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea1396b-b6f6-4d65-9713-0bd6be6808f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for i in range(len(value_with_label[index]['time1'])):\n",
    "    print(value_with_label[index]['time1'][i], value_with_label[index]['time2'][i], value_with_label[index]['corr'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f80049-63ea-4a5a-a6cc-93acef17d65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(time_distribution_base2 | corrs[0] | corrs[2]).save(\"correlations.pdf\", ppi=1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e864bf-a06b-4ab2-b400-6445c4529abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrs[0] | corrs[2]\n",
    "for i in range(3):\n",
    "    (box_plots[i] | corrs[i]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2c3aca-fc07-4c3b-8767-fc5bd8fb0810",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_ternary(session_job_kmeans, \n",
    "                         a=\"wait_for_total\", \n",
    "                         b=\"execution_for_total\",\n",
    "                         c=\"gap_for_total\", \n",
    "                         opacity=0.01, \n",
    "                         color=kmeans.labels_,\n",
    "                        title=\"Session Clustering over the Time Ratio\")\n",
    "fig.update(layout_coloraxis_showscale=False)\n",
    "# fig.write_image('clustering.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1eb260-0859-4770-ba45-b37ea42afaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_job_kmeans = session_job_kmeans.with_row_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20265bd0-f9e1-4587-a8ec-e304bcefcd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_label = pl.DataFrame(kmeans.labels_).rename({'column_0':'label'}).with_row_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0e62b6-26d9-4e73-917f-c444e821e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_job_kmeans = session_job_kmeans.join(kmeans_label, on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e8780-633a-455c-bb30-fe46f725230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_job_kmeans = session_job_kmeans.with_columns(\n",
    "    pl.col(\"index\").cast(pl.String),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3949372f-9d9d-4e9d-a766-40f68f28f67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_job_kmeans.filter(pl.col('label')==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df7f979-fb60-4055-941f-f05a46c7f638",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_chart = alt.Chart(session_job_kmeans).mark_circle(opacity=0.01).encode(\n",
    "    alt.X(\"execution_for_total:Q\", axis=alt.Axis(title='TET / TT (%)', labelFontSize=13, titleFontSize=16, labelAngle=0)),\n",
    "    alt.Y(\"wait_for_total:Q\", axis=alt.Axis(title='TWT / TT (%)', labelFontSize=13, titleFontSize=16, values=[0,20,40,60,80,100])),\n",
    "    alt.Color(\"label:N\").legend(title='cluster',orient=\"top\", labelFontSize=13, labelLimit=200, titleFontSize=0\n",
    "                                 , direction='horizontal', titleOrient='left', symbolType = 'circle', symbolOpacity=1, labelFontWeight = 'bold'\n",
    "                                 , labelExpr=\"{'0':'HWC', '1':'HGC', '2':'HEC'}[datum.label]\"\n",
    "                               )\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20db4bb-6791-40bd-a87a-3446a1c0cfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b9acb7-4f01-4d55-9bbf-963e2eddb206",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_chart.save('session_clustering.png', ppi=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d178a4-69ff-4168-8e8a-6294d7a58a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from altair.expr import datum\n",
    "from vega_datasets import data\n",
    "\n",
    "source = data.jobs.url\n",
    "\n",
    "alt.Chart(source).mark_line().encode(\n",
    "    alt.X('year:O'),\n",
    "    alt.Y('perc:Q', axis=alt.Axis(format='%')),\n",
    "    color=alt.Color('sex:N'),\n",
    ").properties(\n",
    "    title='Percent of work-force working as Welders'\n",
    ").transform_filter(\n",
    "    datum.job == 'Welder'\n",
    ").configure_legend(symbolSize=80, symbolStrokeWidth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e149e5c7-6c18-4561-a2a0-2969fe2a0e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = alt.Chart(session_job).mark_circle(size=60).encode(\n",
    "    x='session_total_wait_time',\n",
    "    y='session_total_run_time',\n",
    ").interactive()\n",
    "\n",
    "base + base.transform_regression('session_total_wait_time', 'session_total_run_time').mark_line().encode(color=alt.value(\"#db646f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37cb139-1983-4b63-8654-5ea7af935bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_total_time_cdf = alt.Chart(session_job_kmeans).transform_window(\n",
    "    ecdf=\"cume_dist()\",\n",
    "    sort=[{\"field\": \"think_for_total\"}],\n",
    ").mark_line(\n",
    "    interpolate=\"step-after\"\n",
    ").encode(\n",
    "    x=\"think_for_total:Q\",\n",
    "    y=\"ecdf:Q\",\n",
    "    text=\"think_for_total\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0382d9-75d8-4128-b09e-95e266e14e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_with_regression(df, x, y):\n",
    "    base = alt.Chart(df).mark_circle(size=30,opacity=0.01).encode(\n",
    "    x=x,\n",
    "    y=y,\n",
    ").interactive()\n",
    "    base = base + base.transform_regression(x, y).mark_line().encode(color=alt.value(\"#db646f\"))\n",
    "    print(df.select(pl.corr(x, y)))\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a91bfa5-3f36-418b-91fb-68b6441cd345",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    chart_with_regression(session_with_label.filter(pl.col('label')==i), 'session_total_run_time', 'session_think_time').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e3f85-77db-4cca-af82-70bafdb0b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_with_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbbdd73-583a-424b-a203-4ac34bc1589b",
   "metadata": {},
   "source": [
    "## User Level Analysis\n",
    "\n",
    "user_1 : x2957a01  \n",
    "user_2 : x2956a03  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf86deec-9b07-433e-b093-f875fa4b10e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "WITH base AS (\n",
    "SELECT \n",
    "    t.*\n",
    "    , json_array_length(nodes) AS node_count\n",
    "    , MAX(end_time) OVER (PARTITION BY user_id ORDER BY submit_time ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS max_end_time\n",
    "FROM {BASE_TABLE}\n",
    "WHERE 1=1\n",
    "{BASE_CONDITION}\n",
    "), base_with_prev_end_time AS (\n",
    "SELECT \n",
    "    base.*\n",
    "    , LAG(base.max_end_time) OVER (PARTITION BY user_id ORDER BY submit_time ASC) AS prev_end_time\n",
    "FROM base\n",
    "), base_with_session_flag AS (\n",
    "SELECT \n",
    "    base_with_prev_end_time.*\n",
    "    , CASE \n",
    "        WHEN prev_end_time > submit_time THEN 0 \n",
    "        ELSE 1 \n",
    "    END AS is_new_session\n",
    "    , MAX(ROUND((JULIANDAY(start_time)-JULIANDAY(prev_end_time)) * 86400), 0) AS additional_wait_s\n",
    "FROM base_with_prev_end_time\n",
    "), base_with_session_id AS (\n",
    "SELECT \n",
    "    base_with_session_flag.*\n",
    "    , CASE WHEN\n",
    "        is_new_session == 1 THEN wait_s\n",
    "        ELSE additional_wait_s\n",
    "    END AS new_wait_s\n",
    "    , SUM(is_new_session) OVER (PARTITION BY user_id ORDER BY submit_time ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS session_id\n",
    "FROM base_with_session_flag\n",
    "), session AS (\n",
    "SELECT \n",
    "    user_id\n",
    "    , session_id\n",
    "    , count(distinct job_name) As job_count\n",
    "    , count(distinct job_name) As job_count_for_sum\n",
    "    , GROUP_CONCAT(distinct job_name) AS job_names\n",
    "    , count(1) AS session_length\n",
    "    , count(1) AS session_length_for_sum\n",
    "    , SUM(new_wait_s) AS session_total_wait_time\n",
    "    , sum(used_walltime) * 1.0 AS total_wall_time\n",
    "    , sum(used_walltime * node_count) * 1.0 AS total_computing_time\n",
    "    , MIN(submit_time) AS first_submit_time\n",
    "    , MIN(start_time) AS first_start_time\n",
    "    , MAX(end_time) AS last_end_time\n",
    "    , MIN(node_count) AS min_node_count\n",
    "    , MAX(node_count) AS max_node_count\n",
    "FROM base_with_session_id\n",
    "GROUP BY 1, 2\n",
    "), session_with_rn AS (\n",
    "SELECT \n",
    "    *\n",
    "    , row_number() over (PARTITION BY user_id ORDER BY first_submit_time ASC) AS rn\n",
    "    , ROUND((JULIANDAY(last_end_time)-JULIANDAY(first_submit_time)) * 86400) - session_total_wait_time AS session_total_run_time\n",
    "FROM session\n",
    "), session_with_think_time AS (\n",
    "SELECT \n",
    "    t1.*\n",
    "    , CASE WHEN\n",
    "        t2.rn IS NULL THEN -1\n",
    "        ELSE ROUND((JULIANDAY(t2.first_submit_time)-JULIANDAY(t1.last_end_time)) * 86400) \n",
    "    END AS session_gap_time\n",
    "    , CASE WHEN\n",
    "        t2.rn IS NULL THEN -1 \n",
    "        ELSE ROUND((JULIANDAY(t2.first_submit_time)-JULIANDAY(t1.first_submit_time)) * 86400)\n",
    "    END AS session_total_time\n",
    "FROM session_with_rn AS t1 \n",
    "    LEFT JOIN session_with_rn AS t2 \n",
    "    ON t1.rn+1 = t2.rn AND t1.user_id = t2.user_id\n",
    ")\n",
    "SELECT\n",
    "    *\n",
    "    , session_total_wait_time AS total_wait_time\n",
    "    , session_total_time AS total_time\n",
    "    , session_total_run_time AS total_execution_time\n",
    "    , session_total_wait_time/session_total_time*100 AS wait_for_total\n",
    "    , session_gap_time/session_total_time*100 AS gap_for_total\n",
    "    , session_total_run_time/session_total_time*100 AS execution_for_total\n",
    "FROM session_with_think_time\n",
    "WHERE 1=1\n",
    "\"\"\"\n",
    "user_job = pl.read_database_uri(query, connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f50ffd-6ba5-4656-8aed-d968afbf65e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_count_figure = alt.Chart(new_user_job.filter(pl.col('session_length')>0).filter(pl.col('session_length')<=100)).mark_line().properties(\n",
    "    width=400,\n",
    "    height=130,\n",
    ").encode(\n",
    "    alt.X(\"session_lengtht:N\", axis=alt.Axis(title='Number of jobs in a sesion', labelFontSize=13, titleFontSize=13, labelAngle=0, values=[10*i for i in range(10)])),\n",
    "    alt.Y(\"session_length\", axis=alt.Axis(title='Job count', labelFontSize=13, titleFontSize=13)),\n",
    ").configure(\n",
    "    numberFormat='.2s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640aa84a-5b0c-40c2-81f6-9849b4bc13a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_job = user_job.group_by('session_length').agg(pl.col(\"session_length_for_sum\").sum())\n",
    "new_user_job = new_user_job.with_columns((pl.col(\"session_length_for_sum\") / 1121803).alias(\"ratio\"))\n",
    "new_user_job = new_user_job.with_columns(pl.lit(\"User\").alias(\"Grouping Condition\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d82753-24cf-4209-b35e-8e3cc18d2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_count_figure = alt.Chart(new_user_job.filter(pl.col('session_length')<=1000).filter(pl.col('session_length')>=1)).mark_line().properties(\n",
    "    width=400,\n",
    "    height=130,\n",
    ").transform_window(\n",
    "    sort=[{'field': 'session_length'}],\n",
    "    cumulative_wheat='sum(ratio)'\n",
    ").encode(\n",
    "    alt.X(\"session_length:Q\", axis=alt.Axis(title='Job Count', labelFontSize=13, titleFontSize=13, labelAngle=0, values=[100*i for i in range(11)])),\n",
    "    alt.Y(\"cumulative_wheat:Q\", axis=alt.Axis(title='Probability', labelFontSize=13, titleFontSize=13)),\n",
    "    alt.Color(\"Grouping Condition\").legend(orient=\"top\", labelFontSize=13, labelLimit=200, titleFontSize=0\n",
    "                                 , direction='horizontal', titleOrient='left', labelFontWeight = 'bold')    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ebab1-2c7e-4af0-ad88-d9233b0a26b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_count_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d206c420-9d9a-40de-a151-7d4c53f518ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_count_figure.save('job_count.png', ppi=1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f76d7a-eb15-4837-b567-ad8e36b69ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_job.filter(pl.col('session_length')==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9ceedb-da70-468f-adc7-546fc0d797ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for row in user_job.filter(pl.col('job_count')>=11).rows(named=True):\n",
    "    if \"openmp\" in row['job_names'].lower():\n",
    "        print(row['job_names'])\n",
    "        print(row)\n",
    "        count += 1\n",
    "    if count == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e67040f-f248-4b02-9e16-3feb41c7b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0 \n",
    "cases_100 = []\n",
    "cases_50 = []\n",
    "# with open('f.txt', 'w') as f:\n",
    "for row in user_job.filter(pl.col('job_count')>=2).rows(named=True):\n",
    "    data = {'distance':cal_distance(row['job_names']), 'job_count':row['job_count']}\n",
    "    if row['job_count'] >= 100:\n",
    "        cases_100.append(data)\n",
    "    cases_50.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7634237d-d5a9-4343-bc2b-2231c09a796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(cases_100, key=lambda x: x['distance'])[83]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5d8c30-7468-424c-a567-81ceedb0611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cases_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a9d3d-e480-440b-a087-ca66ddfb9b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cases_50)):\n",
    "    cases_50[i]['over_100'] = '100+' if cases_50[i]['job_count'] >= 100 else '2-99'\n",
    "for i in range(len(cases_100)):\n",
    "    cases_100[i]['over_100'] = '100+'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445fec37-ca30-4b04-8f71-2481e83470ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_100_df = pl.DataFrame(cases_100)\n",
    "cases_50_df = pl.DataFrame(cases_50)\n",
    "cases_100_graph = alt.Chart(cases_100_df).transform_window(\n",
    "    ecdf=\"cume_dist()\",\n",
    "    sort=[{\"field\": \"distance\"}],\n",
    ").mark_line(\n",
    "    interpolate=\"step-after\"\n",
    ").encode(\n",
    "    alt.X(\"distance:Q\", axis=alt.Axis(title='Levenshtein Distance Ratio', labelFontSize=14, titleFontSize=14, labelAngle=0)),\n",
    "    alt.Y(\"ecdf:Q\", axis=alt.Axis(title='Probability', labelFontSize=14, titleFontSize=14)),\n",
    "    alt.Color(\"over_100:N\").legend(orient=\"top\", labelFontSize=14, labelLimit=200, titleFontSize=0\n",
    "                                 , direction='horizontal', titleOrient='left', labelFontWeight = 'bold')    \n",
    ").properties(\n",
    "    height=110,\n",
    "    width=300\n",
    ")\n",
    "cases_50_graph = alt.Chart(cases_50_df.filter(pl.col('over_100')=='2-99')).transform_window(\n",
    "    ecdf=\"cume_dist()\",\n",
    "    sort=[{\"field\": \"distance\"}],\n",
    ").mark_line(\n",
    "    interpolate=\"step-after\"\n",
    ").encode(\n",
    "    alt.X(\"distance:Q\", axis=alt.Axis(title='Levenshtein Distance Ratio', labelFontSize=14, titleFontSize=14, labelAngle=0)),\n",
    "    alt.Y(\"ecdf:Q\", axis=alt.Axis(title='Probability', labelFontSize=14, titleFontSize=14)),\n",
    "    alt.Color(\"over_100:N\").legend(orient=\"top\", labelFontSize=14, labelLimit=200, titleFontSize=0\n",
    "                                 , direction='horizontal', titleOrient='left', labelFontWeight = 'bold')    \n",
    ").properties(\n",
    "    height=110,\n",
    "    width=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dafbae3-9f5d-4324-8ffb-0058b17840b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.layer(cases_50_graph, cases_100_graph).save('distance.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708123f8-87e9-4868-ade1-b11d2db6d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance, ratio\n",
    "def cal_distance(items):\n",
    "    items = items.split(',')\n",
    "    max_v = collections.defaultdict(int)\n",
    "    distances = 0\n",
    "    count = 0 \n",
    "    for i1 in range(len(items)):\n",
    "        for i2 in range(i1+1,len(items)):\n",
    "            dis = ratio(items[i1], items[i2])\n",
    "            distances += dis\n",
    "            # if dis <=0.5: print(items[i1], items[i2])\n",
    "            count += 1\n",
    "    return distances / count * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8661ff63-027b-4f19-b8f5-50e3181362e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio('abc', 'adef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba1a051-e758-4578-adb1-9fb313821948",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_job.filter(pl.col('session_length')==1).filter(pl.col('session_id')>3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf6ad37-b55f-40f6-9e46-9cbcd4559cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_job.filter(pl.col('user_id')=='x2957a01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ea5a9-d4b4-448d-8d9d-4b1a9b361407",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_job.filter(pl.col('user_id')=='x2956a03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688b4b83-c61c-48ed-9c8a-c65f6a50a65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_job.filter(pl.col('session_length')>1).select(pl.sum('session_length'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02afa9e2-35ab-491b-bef3-d93be7910b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_count = user_job.group_by('job_count').len()\n",
    "job_sum = user_job.group_by('job_count').sum()\n",
    "job_joined = job_count.join(job_sum, on=['job_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203052d8-e134-4c77-88bd-ad32a51e5555",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_lengths = collections.defaultdict(int)\n",
    "total = 0\n",
    "for row in job_joined.rows(named=True):\n",
    "    k, v = row['job_count'], row['len']\n",
    "    job_lengths[k] += v\n",
    "    total += v\n",
    "tmp = 0\n",
    "for k in sorted(job_lengths.keys()):\n",
    "    tmp += (job_lengths[k] * k)\n",
    "    # print(k, job_lengths[k], tmp, tmp/total*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eebc45-f1a8-43f0-ad9e-c4a7ca82b3f1",
   "metadata": {},
   "source": [
    "## Analysis- group level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67299ea-ae07-448d-af4d-80e962b1aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTITION_KEY = \"group_id\"\n",
    "query = f\"\"\"\n",
    "WITH base AS (\n",
    "SELECT \n",
    "    t.*\n",
    "    , json_array_length(nodes) AS node_count\n",
    "    , MAX(end_time) OVER (PARTITION BY {PARTITION_KEY} ORDER BY submit_time ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS max_end_time\n",
    "FROM {BASE_TABLE}\n",
    "WHERE 1=1\n",
    "{BASE_CONDITION}\n",
    "), base_with_prev_end_time AS (\n",
    "SELECT \n",
    "    base.*\n",
    "    , LAG(base.max_end_time) OVER (PARTITION BY {PARTITION_KEY} ORDER BY submit_time ASC) AS prev_end_time\n",
    "FROM base\n",
    "), base_with_session_flag AS (\n",
    "SELECT \n",
    "    base_with_prev_end_time.*\n",
    "    , CASE \n",
    "        WHEN prev_end_time > submit_time THEN 0 \n",
    "        ELSE 1 \n",
    "    END AS is_new_session\n",
    "    , MAX(ROUND((JULIANDAY(start_time)-JULIANDAY(prev_end_time)) * 86400), 0) AS additional_wait_s\n",
    "FROM base_with_prev_end_time\n",
    "), base_with_session_id AS (\n",
    "SELECT \n",
    "    base_with_session_flag.*\n",
    "    , CASE WHEN\n",
    "        is_new_session == 1 THEN wait_s\n",
    "        ELSE additional_wait_s\n",
    "    END AS new_wait_s\n",
    "    , SUM(is_new_session) OVER (PARTITION BY {PARTITION_KEY} ORDER BY submit_time ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS session_id\n",
    "FROM base_with_session_flag\n",
    "), session AS (\n",
    "SELECT \n",
    "    {PARTITION_KEY}\n",
    "    , session_id\n",
    "    , count(distinct job_name) As job_count\n",
    "    , count(distinct job_name) As job_count_for_sum\n",
    "    , GROUP_CONCAT(distinct job_name) AS job_names\n",
    "    , count(1) AS session_length\n",
    "    , count(1) AS session_length_for_sum\n",
    "    , SUM(new_wait_s) AS session_total_wait_time\n",
    "    , sum(used_walltime) * 1.0 AS total_wall_time\n",
    "    , sum(used_walltime * node_count) * 1.0 AS total_computing_time\n",
    "    , MIN(submit_time) AS first_submit_time\n",
    "    , MIN(start_time) AS first_start_time\n",
    "    , MAX(end_time) AS last_end_time\n",
    "    , MIN(node_count) AS min_node_count\n",
    "    , MAX(node_count) AS max_node_count\n",
    "FROM base_with_session_id\n",
    "GROUP BY 1, 2\n",
    "), session_with_rn AS (\n",
    "SELECT \n",
    "    *\n",
    "    , row_number() over (PARTITION BY {PARTITION_KEY} ORDER BY first_submit_time ASC) AS rn\n",
    "    , ROUND((JULIANDAY(last_end_time)-JULIANDAY(first_submit_time)) * 86400) - session_total_wait_time AS session_total_run_time\n",
    "FROM session\n",
    "), session_with_think_time AS (\n",
    "SELECT \n",
    "    t1.*\n",
    "FROM session_with_rn AS t1 \n",
    "    LEFT JOIN session_with_rn AS t2 \n",
    "    ON t1.rn+1 = t2.rn AND t1.{PARTITION_KEY} = t2.{PARTITION_KEY}\n",
    ")\n",
    "SELECT     *\n",
    "FROM session_with_think_time\n",
    "WHERE 1=1\n",
    "\"\"\"\n",
    "group_job = pl.read_database_uri(query, connection_string)\n",
    "    # , CASE WHEN\n",
    "    #     t2.rn IS NULL THEN -1\n",
    "    #     ELSE ROUND((JULIANDAY(t2.first_submit_time)-JULIANDAY(t1.last_end_time)) * 86400) \n",
    "    # END AS session_gap_time\n",
    "    # , CASE WHEN\n",
    "    #     t2.rn IS NULL THEN -1 \n",
    "    #     ELSE ROUND((JULIANDAY(t2.first_submit_time)-JULIANDAY(t1.first_submit_time)) * 86400)\n",
    "    # END AS session_total_time\n",
    "\n",
    "# , session_gap_time/session_total_time*100 AS gap_for_total\n",
    "    # , session_total_wait_time AS total_wait_time\n",
    "    # , session_total_time AS total_time\n",
    "    # , session_total_run_time AS total_execution_time\n",
    "    # , session_total_wait_time/session_total_time*100 AS wait_for_total\n",
    "    # , session_total_run_time/session_total_time*100 AS execution_for_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc7a820-3e23-458d-8469-eb4b20164608",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_count_figure = alt.Chart(new_group_job.filter(pl.col('session_length')<=1000).filter(pl.col('session_length')>=1)).mark_line().properties(\n",
    "    width=400,\n",
    "    height=130,\n",
    ").transform_window(\n",
    "    sort=[{'field': 'session_length'}],\n",
    "    cumulative_wheat='sum(ratio)'\n",
    ").encode(\n",
    "    alt.X(\"session_length:Q\", axis=alt.Axis(title='Job Count', labelFontSize=13, titleFontSize=13, labelAngle=0, values=[100*i for i in range(11)])),\n",
    "    alt.Y(\"cumulative_wheat:Q\", axis=alt.Axis(title='Probability', labelFontSize=13, titleFontSize=13)),\n",
    "    alt.Color(\"Grouping Condition\").legend(orient=\"top\", labelFontSize=13, labelLimit=200, titleFontSize=0\n",
    "                                 , direction='horizontal', titleOrient='left', labelFontWeight = 'bold')    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98844fde-dae3-487c-9206-17086cd235e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_group_job.filter(pl.col('session_length')==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41828af0-dee8-4f23-88e9-b6b86abf6984",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_group_job = group_job.group_by('session_length').agg(pl.col(\"session_length_for_sum\").sum())\n",
    "new_group_job = new_group_job.with_columns((pl.col(\"session_length_for_sum\") / 1121803).alias(\"ratio\"))\n",
    "new_group_job = new_group_job.with_columns(pl.lit(\"Group\").alias(\"Grouping Condition\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dc3333-bee3-4bad-84fb-d7d401d8ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_group_job.filter(pl.col('session_length')<1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b73e04f-72df-4438-b94a-d4ab0e1e7486",
   "metadata": {},
   "source": [
    "## Analysis Considering node_count\n",
    "\n",
    "•\tIn most cases, the jobs within a session have the same node_count.  \n",
    "•\tThe number of sessions where node_count remains consistent is 390,046, while sessions with varying node_count total 2,395.  \n",
    "•\tAmong sessions with more than two jobs, there are 40,612 consistent sessions and 2,395 inconsistent ones.  \n",
    "•\tOverall, 94.4% of sessions maintain the same node_count across all jobs.  \n",
    "\n",
    "⸻\n",
    "\n",
    "Distributions by node_count  \n",
    "\t•\tThe distributions of wait_time, run_time, and computing_time tend to increase as node_count increases.  \n",
    "\t•\tConversely, wall_time, think_time, and total_time tend to decrease with larger node_count.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0121c2b8-4092-4efb-a9df-9a7ea8719c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "WITH base AS (\n",
    "SELECT \n",
    "    t.*\n",
    "    , json_array_length(nodes) AS node_count\n",
    "    , MAX(end_time) OVER (PARTITION BY user_id, job_name ORDER BY submit_time ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS max_end_time\n",
    "FROM {BASE_TABLE}\n",
    "WHERE 1=1\n",
    "{BASE_CONDITION}\n",
    "), base_with_prev_end_time AS (\n",
    "SELECT \n",
    "    base.*\n",
    "    , LAG(base.max_end_time) OVER (PARTITION BY user_id, job_name ORDER BY submit_time ASC) AS prev_end_time\n",
    "FROM base\n",
    "), base_with_session_flag AS (\n",
    "SELECT \n",
    "    base_with_prev_end_time.*\n",
    "    , CASE \n",
    "        WHEN prev_end_time > submit_time THEN 0 \n",
    "        ELSE 1 \n",
    "    END AS is_new_session\n",
    "    , MAX(ROUND((JULIANDAY(start_time)-JULIANDAY(prev_end_time)) * 86400), 0) AS additional_wait_s\n",
    "FROM base_with_prev_end_time\n",
    "), base_with_session_id AS (\n",
    "SELECT \n",
    "    base_with_session_flag.*\n",
    "    , CASE WHEN\n",
    "        is_new_session == 1 THEN wait_s\n",
    "        ELSE additional_wait_s\n",
    "    END AS new_wait_s\n",
    "    , SUM(is_new_session) OVER (PARTITION BY user_id, job_name ORDER BY submit_time ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS session_id\n",
    "FROM base_with_session_flag\n",
    "), session AS (\n",
    "SELECT \n",
    "    user_id\n",
    "    , job_name\n",
    "    , session_id\n",
    "    , count(1) AS session_length\n",
    "    , SUM(new_wait_s) AS session_total_wait_time\n",
    "    , SUM(run_s) AS total_wall_time\n",
    "    , SUM(run_s * node_count) AS total_computing_time\n",
    "    , MIN(submit_time) AS first_submit_time\n",
    "    , MIN(start_time) AS first_start_time\n",
    "    , MAX(end_time) AS last_end_time\n",
    "    , MIN(node_count) AS min_node_count\n",
    "    , MAX(node_count) AS max_node_count\n",
    "FROM base_with_session_id\n",
    "GROUP BY 1, 2, 3\n",
    "), session_with_rn AS (\n",
    "SELECT \n",
    "    *\n",
    "    , row_number() over (PARTITION BY user_id, job_name ORDER BY first_submit_time ASC) AS rn\n",
    "    , ROUND((JULIANDAY(last_end_time)-JULIANDAY(first_submit_time)) * 86400) - session_total_wait_time AS session_total_run_time\n",
    "FROM session\n",
    "), session_with_think_time AS (\n",
    "SELECT \n",
    "    t1.*\n",
    "    , CASE WHEN\n",
    "        t2.rn IS NULL THEN -1\n",
    "        ELSE ROUND((JULIANDAY(t2.first_submit_time)-JULIANDAY(t1.last_end_time)) * 86400) \n",
    "    END AS session_gap_time\n",
    "    , CASE WHEN\n",
    "        t2.rn IS NULL THEN -1 \n",
    "        ELSE ROUND((JULIANDAY(t2.first_submit_time)-JULIANDAY(t1.first_submit_time)) * 86400)\n",
    "    END AS session_total_time\n",
    "FROM session_with_rn AS t1 \n",
    "    LEFT JOIN session_with_rn AS t2 \n",
    "    ON t1.rn+1 = t2.rn AND t1.user_id = t2.user_id AND t1.job_name = t2.job_name\n",
    ")\n",
    "SELECT\n",
    "    *\n",
    "    , session_total_wait_time AS total_wait_time\n",
    "    , session_total_time AS total_time\n",
    "    , session_total_run_time AS total_execution_time\n",
    "    , session_total_wait_time/session_total_time*100 AS wait_for_total\n",
    "    , session_gap_time/session_total_time*100 AS gap_for_total\n",
    "    , session_total_run_time/session_total_time*100 AS execution_for_total\n",
    "    , CASE WHEN min_node_count = max_node_count THEN 'Identical'\n",
    "    ELSE 'Dynamic' END AS have_same_node_count\n",
    "FROM session_with_think_time\n",
    "WHERE 1=1\n",
    "\"\"\"\n",
    "session_job_with_node = pl.read_database_uri(query, connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb904b0-5d22-4be1-ab72-b1b02ab7af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_job_with_node.filter(pl.col('session_length')>1).filter(pl.col('have_same_node_count')==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8814243-fee9-4e67-ac9e-b15724f43fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_job_with_tmp = collections.defaultdict(int)\n",
    "session_job_with_tmp_key = collections.defaultdict(int)\n",
    "for row in session_job_with_node.rows(named=True):\n",
    "    session_job_with_tmp[(row['session_length'], row['have_same_node_count'])] += 1\n",
    "    session_job_with_tmp_key[row['session_length']] += 1\n",
    "for k in session_job_with_tmp:\n",
    "    l, _ = k\n",
    "    session_job_with_tmp[k] /= session_job_with_tmp_key[l]\n",
    "df_tmp = []\n",
    "for k in session_job_with_tmp:\n",
    "    l, v = k\n",
    "    df_tmp.append({'session_length':l, 'ratio':session_job_with_tmp[k]*100, 'have_same_node_count':v})\n",
    "session_job_df = pl.DataFrame(df_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34c3c68-ecb3-4dd0-95e0-e6f6cf804d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_job_df.filter(pl.col('session_length')==20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b62aa2-e8e6-4246-9602-cf957e8bf68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_count_identical = alt.Chart(session_job_df.filter(pl.col('session_length')>1).filter(pl.col('session_length')<21).rename({\"have_same_node_count\": \"Node Count\"})).mark_bar(width=12).properties(\n",
    "    width=400,\n",
    "    height=130,\n",
    ").encode(\n",
    "    alt.X('session_length:Q', axis=alt.Axis(title='Node Count', labelFontSize=13, titleFontSize=15), scale=alt.Scale(domain=[2, 20])),\n",
    "    alt.Y('ratio:Q', axis=alt.Axis(title='Ratio(%)', labelFontSize=13, titleFontSize=15\n",
    "         )),\n",
    "    alt.Color(\"Node Count:N\").legend(orient=\"top\", labelFontSize=13, labelLimit=200, titleFontSize=0\n",
    "    , direction='horizontal', titleOrient='left', columnPadding=40, labelFontWeight = 'bold')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6807c7-2d3f-4552-a0c2-4a55a24eaa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_count_identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3450a359-37fc-48a2-9e62-c607d2747cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_count_identical.save('node_count_identical.pdf', ppi=1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35885e02-7aa5-46ec-a2b6-5b4095f384eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_count_lengths = collections.defaultdict(int)\n",
    "total = 0\n",
    "for row in session_job_with_node_filter.group_by('min_node_count').len().rows(named=True):\n",
    "    k, v = row['min_node_count'], row['len']\n",
    "    node_count_lengths[k] += v\n",
    "    total += v\n",
    "tmp = 0\n",
    "for k in sorted(node_count_lengths.keys()):\n",
    "    tmp += node_count_lengths[k]\n",
    "    # print(k, node_count_lengths[k], tmp, tmp/total*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688fef74-a9f7-4038-96c6-efff282e0a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_count_distribution = alt.Chart(session_job_with_node_filter.filter(pl.col('min_node_count')<=16)).mark_line(point=True).properties(\n",
    "    width=400,\n",
    "    height=100,\n",
    ").encode(\n",
    "    alt.X(\"min_node_count:N\", axis=alt.Axis(title='Node Count', labelFontSize=13, values=[1,2,4,8,16,32], titleFontSize=13, labelAngle=0)),\n",
    "    alt.Y(\"count()\", axis=alt.Axis(title='Count', labelFontSize=13, titleFontSize=13)),\n",
    ").configure(\n",
    "    numberFormat='.2s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f507b-1095-4f72-bb3b-407b876298a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_job_with_node.filter(pl.col('session_length')>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10324fc-ebfa-4de0-b858-7315d332de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(session_job_with_node.filter(pl.col('min_node_count')<=16)).mark_line(point=True).properties(\n",
    "    width=400,\n",
    "    height=100,\n",
    ").encode(\n",
    "    alt.X(\"min_node_count:N\", axis=alt.Axis(title='Node Count', labelFontSize=13, values=[1,2,4,8,16,32], titleFontSize=13, labelAngle=0)),\n",
    "    alt.Y(\"count()\", axis=alt.Axis(title='Count', labelFontSize=13, titleFontSize=13)),\n",
    ").configure(\n",
    "    numberFormat='.2s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ccb949-4297-4701-a2e0-ed821dbcacfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_count_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a9dd6-f8c2-4f3f-aaf2-e96dedf2db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_count_distribution.save('"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9be14-8856-4340-b419-ea888e9ba823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_node_count(df, time1):\n",
    "    df = df.filter(pl.col(time1)>0)\n",
    "    corr = df.select(pl.corr('min_node_count',time1)).row(index=0)[0]\n",
    "    return corr\n",
    "\n",
    "times = ['total_wait_time', 'total_execution_time', 'total_wall_time', 'total_computing_time','session_gap_time', 'total_time']\n",
    "for time in times:\n",
    "    print(time, get_corr_node_count(session_job_with_node_filter, time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9a591a-c82c-496c-b89c-3d231e05714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(plots[0] | plots[1] | plots[2] | plots[3] | plots[4] | plots[5]).save('node_count.pdf', ppi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9bddb6-a6c8-4bff-9b56-1f2af442fb43",
   "metadata": {},
   "source": [
    "## Prediction Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5e4e7f-1ddb-4a8a-b091-c2a054f0e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f08f81-59da-4ba5-8c61-e4d855a9838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_with_label.filter(pl.col('label')==0).describe(percentiles=[0.05, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ccd9a6-89b3-4f8f-908e-5b00939cbf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = '2024-05-01'\n",
    "train = session_with_label.filter(pl.col('first_submit_time')<time)\n",
    "# .filter(pl.col('session_gap_time')>=165.0).filter(pl.col('session_gap_time')<=101959.0)\n",
    "test = session_with_label.filter(pl.col('first_submit_time')>=time)\n",
    "# .filter(pl.col('session_gap_time')>=165.0).filter(pl.col('session_gap_time')<=101959.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c592965-f12f-4f7a-9803-e05df8a2114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f8133c-5fe4-4e4b-9692-44b6d7c0f28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0,2]\n",
    "variables = [['total_wait_time', 'total_execution_time'], ['total_execution_time'], ['total_wait_time']]\n",
    "# models = [LinearRegression(), RandomForestRegressor(n_estimators=100, random_state=42), xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)]\n",
    "models = [xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)]\n",
    "y_preds = {}\n",
    "for label in labels:\n",
    "    for model in models:\n",
    "        for variable_index in range(len(variables)):\n",
    "            labeld = train.filter(pl.col('label')==label)\n",
    "            # labeld = train\n",
    "            X_train = labeld.select(variables[variable_index])\n",
    "            y_train = labeld.select('session_gap_time')\n",
    "            test_labeld = test.filter(pl.col('label')==label)\n",
    "            # test_labeld = test\n",
    "            X_test = test_labeld.select(variables[variable_index])\n",
    "            y_test = test_labeld.select('session_gap_time')\n",
    "            model.fit(X_train, y_train)        \n",
    "            y_pred = model.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            y_preds[(label,variable_index)] = y_pred\n",
    "            print(label, variable_index, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d656362-7742-4da7-9670-f95ceaec5358",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_graph(0).save('prediction_high_wait.pdf', ppi=100)\n",
    "get_graph(2).save('prediction_high_execution.pdf', ppi=100)\n",
    "# get_graph(0).save('prediction_whole_time.pdf', ppi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9702c3c1-ae1f-4393-b12f-3cdfd1121a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(label):\n",
    "    label_0 = test.filter(pl.col('label')==label)\n",
    "    y_test = label_0.select('session_gap_time')\n",
    "    y_test = y_test.to_dicts()\n",
    "    label_yy = []\n",
    "    graph = []\n",
    "    for j in range(len(variables)):\n",
    "        label_yy = []\n",
    "        for i in range(len(y_test)):\n",
    "            label_yy.append({'y_test':y_test[i]['session_gap_time'], 'y_predict':y_preds[(label,j)][i]})\n",
    "        df = pl.DataFrame(label_yy).filter(pl.col('y_predict')<200000).filter(pl.col('y_test')<200000).filter(pl.col('y_test')>0).filter(pl.col('y_predict')>0)\n",
    "        base = alt.Chart(df).mark_circle(size=20,opacity=0.1).encode(\n",
    "            x='y_test',\n",
    "            y='y_predict',\n",
    "        ).interactive()\n",
    "        base2 = alt.Chart(df).mark_line(color='red').encode(\n",
    "            x='y_test',\n",
    "            y='y_test',\n",
    "        ).interactive()\n",
    "        chart = (base+base2).encode(\n",
    "        x=alt.X(axis=alt.Axis(title='Session Gap Time (Actual)', labelFontSize=22, titleFontSize=22, values=[0,50000,100000,150000,200000])),\n",
    "        y=alt.Y(axis=alt.Axis(title='Session Gap Time (Prediction)', labelFontSize=22, titleFontSize=22, values=[0,50000,100000,150000,200000], labelAngle=-90))\n",
    "        ).configure(\n",
    "        numberFormat='.2s'\n",
    "        )\n",
    "        graph.append(chart)\n",
    "    return graph[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
